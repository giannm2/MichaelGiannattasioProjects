---
title: "Submission4"
author: "Michael Giannattasio"
date: '2022-04-23'
output: html_document
---

```{r, include=FALSE, set.seed(20)}
knitr::opts_chunk$set(cache = T)

# Set the correct default repository
r = getOption("repos")
r["CRAN"] = "http://cran.rstudio.com"
options(repos = r)


# These will install required packages if they are not already installed
if (!require("ggplot2")) {
   install.packages("ggplot2", dependencies = TRUE)
   library(ggplot2)
}
if (!require("knitr")) {
   install.packages("knitr", dependencies = TRUE)
   library(knitr)
}
if (!require("xtable")) {
   install.packages("xtable", dependencies = TRUE)
   library(xtable)
}
if (!require("pander")) {
   install.packages("pander", dependencies = TRUE)
   library(pander)
}

if (!require("devtools")) {
  install.packages("devtools",dependencies = TRUE ) 
  library(devtools)
}

if (!require("usethis")) {
  install.packages("usethis" ) 
  library(usethis)
}

if (!require("e1071")) {
 install.packages("e1071" ) 
  library(e1071)
}

if (!require("pROC")){
  install.packages("pROC")
   library(pROC)
} 

if (!require("dplyr")) {
   install.packages("dplyr", dependencies = TRUE)
   library(dplyr)
}

if (!require("tidyverse")) {
   install.packages("tidyverse", dependencies = TRUE)
   library(tidyverse)
}

if (!require("caret")) {
   install.packages("caret", dependencies = TRUE)
   library(caret)
}

if (!require("Boruta")) {
   install.packages("Boruta", dependencies = TRUE)
   library(Boruta)
}

if (!require("randomForest")) {
   install.packages("randomForest", dependencies = TRUE)
   library(randomForest)
}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Prepare biodegradability data 
#get feature names 
featurenames <- read.csv("~/MATP-4400/data/chems_feat.name.csv",
                         header=FALSE, 
                         colClasses = "character")

# get training data and rename with feature names
cdata.df <-read.csv("~/MATP-4400/data/chems_train.data.csv",
                    header=FALSE)
colnames(cdata.df) <- featurenames$V1

# get external testing data and rename with feature names
tdata.df <-read.csv("~/MATP-4400/data/chems_test.data.csv",
                    header=FALSE) 

colnames(tdata.df) <- featurenames$V1

class <- read.csv("~/MATP-4400/data/chems_train.solution.csv",
                  header=FALSE, 
                  colClasses = "factor") 

class <- class$V1
```

## Preparing the Data: Create Training & Validation datasets

We split the data into **90% train** and **10% validation** datasets.

\tiny
```{r}
#ss will be the number of data points in the training set
n <- nrow(cdata.df)
ss <- ceiling(n*0.90)

# Set random seed for reproducibility
set.seed(200)
train.perm <- sample(1:n,ss)

#Split training and validation data
train <- cdata.df %>% dplyr::slice(train.perm) 
validation <- cdata.df %>% dplyr::slice(-train.perm) 
```

## Preparing the Data: Create Training & Validation datasets (2)

We then standardize all variables to a _common scale_, since we don't have domain knowledge and LR assumes independent and identically distributed (IID) Gaussian features. This avoids LR unwittingly prioritizing certain features simply because their scale is larger.  

Note that the training, validation sets, are all scaled identically using the `preProcess()`.

\tiny
```{r}
# Initialize the `scaler` on the training data
#   method = "center" subtracts the mean of the predictor's data from the predictor values
#   method = "scale" divides by the standard deviation.
#   NOTE: See `?preProcess` for other methods
scaler <- preProcess(train, method = c("center", "scale")) 

# Use the `scale` object to normalize our training data
train <- predict(scaler, train) 
#summary(train[,1:4])

# Normalize validation data
validation <- predict(scaler, validation) 

# Normalize testing data
test <- predict(scaler, tdata.df) 

# Split the output classes
classtrain <- class[train.perm]
classval <-class[-train.perm]
```

Random Forest w/ no selection
```{r}
classtrainFactor <- as.factor(classtrain)
train.df <- cbind(train,classtrainFactor)
RFtrain <- randomForest(classtrainFactor~., data=train.df, 
                        importance = TRUE,
                        proximity = TRUE)

# Predict validation (OUTPUTS PROBABILITIES)
rankingRFval <- as.numeric(predict(RFtrain,validation,
                          type="prob"))

rankingRFfinal <- as.numeric(predict(RFtrain,test,
                          type="prob"))
```

```{r}
# no need to convert to 0 and 1 since ranking needed for AUC.
write.table(rankingRFfinal,file = "classification.csv", row.names=F, col.names=F)
```

\tiny
```{r}
# Here is the mean prediction file for submission to the website 
# features should be a column vector of 0's and 1's. 
# 1 = keep feature, 0 = don't
features<-matrix(1,nrow=(ncol(train)),ncol=1)
rownames(features) <- colnames(train)

write.table(features,file = "selection.csv", row.names=F, col.names=F)
```

\tiny
```{r}
# get time
time <-  format(Sys.time(), "%H%M%S")

#This automatically generates a compressed (zip) file 
system(paste0("zip -u JSEEntry-", time, ".csv.zip classification.csv"))
system(paste0("zip -u JSEEntry-", time, ".csv.zip selection.csv"))

paste0("The name of your entry file: JSEEntry-", time, ".csv.zip")
```

Random Forest w/ Boruta selection
```{r, warning=FALSE}
trainNoFac.df <- cbind(train,classtrain)
borutaTrain <- Boruta(classtrain~., data=trainNoFac.df, doTrace = 2)

borutaFinal <- TentativeRoughFix(borutaTrain)
features <- getSelectedAttributes(borutaFinal)

significant.variables <- colnames(train) %in% features
significant.variables <- as.data.frame(significant.variables)
rownames(significant.variables)<- colnames(train)
significant.variables <- as.matrix(significant.variables)
```

```{r}
trainBoruta <- train %>% select_if(significant.variables)
trainBoruta <- cbind(trainBoruta, classtrainFactor)

BorutaRFmodel <- randomForest(classtrainFactor~., data=trainBoruta, 
                        importance = TRUE,
                        proximity = TRUE)
```

\tiny
```{r}
# Predict the test data (OUTPUTS LOG-ODDS) to get rankings
rankingRFtest <- as.numeric(predict(BorutaRFmodel, test))

# no need to convert to 0 and 1 since ranking needed for AUC.
write.table(rankingRFtest,file = "classification.csv", row.names=F, col.names=F)
```

\tiny
```{r}
# Here is the mean prediction file for submission to the website 
# features should be a column vector of 0's and 1's. 
# 1 = keep feature, 0 = don't
features<-matrix(0,nrow=(ncol(train)),ncol=1)
rownames(features) <- colnames(train)

# Set the ones we want to keep to 1
features[significant.variables,1] <- 1
write.table(features,file = "selection.csv", row.names=F, col.names=F)
```

\tiny
```{r}
# get time
time <-  format(Sys.time(), "%H%M%S")

#This automatically generates a compressed (zip) file 
system(paste0("zip -u JSEEntry-", time, ".csv.zip classification.csv"))
system(paste0("zip -u JSEEntry-", time, ".csv.zip selection.csv"))

paste0("The name of your entry file: JSEEntry-", time, ".csv.zip")
```
